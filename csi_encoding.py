# -*- coding: utf-8 -*-
"""CSI_encoding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cawZWR1LIUuOkVKOHzx1yXTuhW3O22il
"""

# CSI encoding

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import os

TOTAL_TEST_SYMBOLS = 200000  # 원하는 심볼 개수
VIZ_SNR_TARGET = 20          # 성상도 확인 목표 SNR (dB)

def map_weights_to_conductance_linear(weights_matrix, g_min, g_max, num_states, non_linearity, max_weight_for_scaling):
    if num_states <= 1: return np.full_like(weights_matrix, g_min)
    p_levels = np.linspace(0, 1, num_states)
    alpha = 1 + non_linearity
    p_nonlinear = p_levels ** alpha
    achievable_conductances_lut = g_min + p_nonlinear * (g_max - g_min)

    if max_weight_for_scaling == 0: return np.full_like(weights_matrix, g_min)

    scaled_matrix = g_min + (weights_matrix / max_weight_for_scaling) * (g_max - g_min)
    scaled_matrix = np.clip(scaled_matrix, g_min, g_max)

    shape = scaled_matrix.shape
    scaled_flat = scaled_matrix.flatten()

    diff = np.abs(scaled_flat[:, np.newaxis] - achievable_conductances_lut)
    closest_indices = np.argmin(diff, axis=1)
    rram_flat = achievable_conductances_lut[closest_indices]

    return rram_flat.reshape(shape)

class CSI_Autoencoder(nn.Module):
    def __init__(self, input_dim, compressed_dim):
        super(CSI_Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.BatchNorm1d(64),
            nn.LeakyReLU(0.1),
            nn.Linear(64, 32),
            nn.LeakyReLU(0.1),
            nn.Linear(32, compressed_dim)
        )
        self.decoder = nn.Sequential(
            nn.Linear(compressed_dim, 32),
            nn.LeakyReLU(0.1),
            nn.Linear(32, 64),
            nn.LeakyReLU(0.1),
            nn.Linear(64, input_dim)
        )
    def forward(self, x):
        return self.decoder(self.encoder(x))

def generate_channel_data(num_samples, Nt):
    H_complex = (np.random.randn(num_samples, Nt) + 1j * np.random.randn(num_samples, Nt)) / np.sqrt(2)
    H_real = np.concatenate([np.real(H_complex), np.imag(H_complex)], axis=1)
    return torch.FloatTensor(H_real), H_complex

def qam16_modulator(num_symbols):
    levels = np.array([-3, -1, 1, 3]) / np.sqrt(10)
    real_parts = np.random.choice(levels, num_symbols)
    imag_parts = np.random.choice(levels, num_symbols)
    return real_parts + 1j * imag_parts

def qam16_demodulator_hard(received_symbols):
    levels = np.array([-3, -1, 1, 3]) / np.sqrt(10)
    constellation = np.array([r + 1j*i for r in levels for i in levels])
    dists = np.abs(received_symbols[:, None] - constellation[None, :])
    return constellation[np.argmin(dists, axis=1)]

def rram_inference(input_vector, weight_matrix, bias_vector, rram_params):
    g_min, g_max, num_states, nonlinearity, read_noise_std = rram_params
    weight_matrix = np.clip(weight_matrix, -1.0, 1.0)
    min_w = np.min(weight_matrix)
    offset_w = -min_w if min_w < 0 else 0
    target_w = weight_matrix + offset_w
    max_w = np.max(target_w)
    G_rram = map_weights_to_conductance_linear(target_w, g_min, g_max, num_states, nonlinearity, max_w)
    gain_slope = (g_max - g_min) / max_w if max_w > 0 else 1

    I_out_raw = input_vector @ G_rram.T
    noise_scale = np.mean(np.abs(I_out_raw)) * read_noise_std
    I_out_noisy = I_out_raw + np.random.normal(0, noise_scale, I_out_raw.shape)

    input_sum = np.sum(input_vector, axis=1, keepdims=True)
    I_removed_bias = I_out_noisy - (input_sum * g_min)
    output = (I_removed_bias / gain_slope) - (input_sum * offset_w)

    if bias_vector is not None: output += bias_vector
    return output

def main():

    SEED = 20
    np.random.seed(SEED)
    torch.manual_seed(SEED)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(SEED)

    Nt = 4; Input_Dim = 2 * Nt; Compression_Ratio = 2
    Compressed_Dim = Input_Dim // Compression_Ratio
    Num_Train = 10000; Num_Test = 1000; Epochs = 2000
    rram_params = (1e-3, 8e-3, 76, 0.38, 0.0025)

    print(f"--- 6G Massive MIMO CSI Compression (Unified Simulation) ---")
    print(f"Target Total Symbols: {TOTAL_TEST_SYMBOLS}")

    train_data, _ = generate_channel_data(Num_Train, Nt)
    test_data, test_data_complex = generate_channel_data(Num_Test, Nt)

    model = CSI_Autoencoder(Input_Dim, Compressed_Dim)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()

    print("Training AI Model...")
    model.train()
    for epoch in range(Epochs):
        optimizer.zero_grad()
        loss = criterion(model(train_data), train_data)
        loss.backward()
        optimizer.step()
        with torch.no_grad():
            for param in model.parameters(): param.clamp_(-1.0, 1.0)
    print("Training Complete.")

    model.eval()
    def rram_encoder_forward(x_input, model, params):
        x_np = x_input.detach().numpy()
        out1 = rram_inference(x_np, model.encoder[0].weight.detach().numpy(), model.encoder[0].bias.detach().numpy(), params)
        out1_act = model.encoder[2](model.encoder[1](torch.FloatTensor(out1)))
        out2 = rram_inference(out1_act.detach().numpy(), model.encoder[3].weight.detach().numpy(), model.encoder[3].bias.detach().numpy(), params)
        out2_act = model.encoder[4](torch.FloatTensor(out2))
        out3 = rram_inference(out2_act.detach().numpy(), model.encoder[5].weight.detach().numpy(), model.encoder[5].bias.detach().numpy(), params)
        return torch.FloatTensor(out3)

    print("Reconstructing Channels via RRAM Matrix...")
    encoded_ideal = model.encoder(test_data)
    decoded_ideal = model.decoder(encoded_ideal)

    encoded_rram = rram_encoder_forward(test_data, model, rram_params)
    decoded_rram = model.decoder(encoded_rram)

    def calc_nmse(original, reconstructed):
        orig_np = original.detach().numpy()
        recon_np = reconstructed.detach().numpy()

        mse = np.mean((orig_np - recon_np)**2)
        power = np.mean(orig_np**2)
        return 10 * np.log10(mse / power)

    nmse_ideal = calc_nmse(test_data, decoded_ideal)
    nmse_rram = calc_nmse(test_data, decoded_rram)

    print(f"\n[Result] Ideal NMSE: {nmse_ideal:.2f} dB")
    print(f"[Result] RRAM NMSE: {nmse_rram:.2f} dB")

    H_recon_ideal = decoded_ideal.detach().numpy()[:, :Nt] + 1j * decoded_ideal.detach().numpy()[:, Nt:]
    H_recon_rram = decoded_rram.detach().numpy()[:, :Nt] + 1j * decoded_rram.detach().numpy()[:, Nt:]
    H_true = test_data_complex

    snr_range = np.arange(0, 25, 4)
    ser_results = []

    saved_constellation_data = None

    print("\nStarting Communication Simulation...")

    for snr in snr_range:
        n0 = 1.0 / (10**(snr/10.0))
        err_p_total = 0; err_i_total = 0; err_r_total = 0

        collect_data = (snr == VIZ_SNR_TARGET)

        if collect_data:
            list_tx = []; list_rx_p = []; list_rx_i = []; list_rx_r = []

        batch_size = 1000
        num_batches = int(np.ceil(TOTAL_TEST_SYMBOLS / batch_size))
        processed_symbols = 0

        for b in range(num_batches):
            current_batch_size = min(batch_size, TOTAL_TEST_SYMBOLS - processed_symbols)
            ch_idx = b % len(H_true)

            h_t = H_true[ch_idx]
            h_i = H_recon_ideal[ch_idx]
            h_r = H_recon_rram[ch_idx]

            w_p = np.conj(h_t)/np.linalg.norm(h_t)
            w_i = np.conj(h_i)/np.linalg.norm(h_i)
            w_r = np.conj(h_r)/np.linalg.norm(h_r)

            s_batch = qam16_modulator(current_batch_size)
            noise = np.sqrt(n0/2) * (np.random.randn(current_batch_size) + 1j*np.random.randn(current_batch_size))

            y_p = h_t @ np.outer(w_p, s_batch) + noise
            y_i = h_t @ np.outer(w_i, s_batch) + noise
            y_r = h_t @ np.outer(w_r, s_batch) + noise

            rx_p = y_p / (h_t @ w_p)
            rx_i = y_i / (h_t @ w_i)
            rx_r = y_r / (h_t @ w_r)

            d_p = qam16_demodulator_hard(rx_p)
            d_i = qam16_demodulator_hard(rx_i)
            d_r = qam16_demodulator_hard(rx_r)

            err_p_total += np.sum(d_p != s_batch)
            err_i_total += np.sum(d_i != s_batch)
            err_r_total += np.sum(d_r != s_batch)

            if collect_data:
                list_tx.append(s_batch.flatten())
                list_rx_p.append(rx_p.flatten())
                list_rx_i.append(rx_i.flatten())
                list_rx_r.append(rx_r.flatten())

            processed_symbols += current_batch_size

        ser_p = err_p_total / TOTAL_TEST_SYMBOLS
        ser_i = err_i_total / TOTAL_TEST_SYMBOLS
        ser_r = err_r_total / TOTAL_TEST_SYMBOLS

        print(f"SNR {snr}dB -> Tested {TOTAL_TEST_SYMBOLS} symbols. RRAM SER: {ser_r:.6f}")
        ser_results.append([snr, ser_p, ser_i, ser_r])

        if collect_data:
            saved_constellation_data = {
                'Tx': np.concatenate(list_tx).flatten(),
                'Rx_Perfect': np.concatenate(list_rx_p).flatten(),
                'Rx_Ideal': np.concatenate(list_rx_i).flatten(),
                'Rx_RRAM': np.concatenate(list_rx_r).flatten()
            }
            print(f"  >> Captured {len(saved_constellation_data['Tx'])} points for visualization.")

    df_nmse = pd.DataFrame({
        'Metric': ['Ideal_NMSE_dB', 'RRAM_NMSE_dB'],
        'Value': [nmse_ideal, nmse_rram]
    })
    df_nmse.to_csv('simulation_nmse_results.csv', index=False)
    print("\n[Saved] NMSE results to 'simulation_nmse_results.csv'")

    df_ser = pd.DataFrame(ser_results, columns=['SNR_dB', 'SER_Perfect', 'SER_Ideal_AI', 'SER_RRAM_AI'])
    df_ser.to_csv('simulation_ser_results_unified.csv', index=False)
    print("[Saved] SER results to 'simulation_ser_results_unified.csv'")

    if saved_constellation_data is not None:
        df_const = pd.DataFrame({
            'Tx_Real': np.real(saved_constellation_data['Tx']),
            'Tx_Imag': np.imag(saved_constellation_data['Tx']),
            'Rx_RRAM_Real': np.real(saved_constellation_data['Rx_RRAM']),
            'Rx_RRAM_Imag': np.imag(saved_constellation_data['Rx_RRAM']),
        })
        df_const.to_csv('qam_constellation_data_unified.csv', index=False)
        print(f"[Saved] {TOTAL_TEST_SYMBOLS} points of Constellation data.")
    else:
        print("[Warning] Target VIZ_SNR was not in the snr_range.")

    plt.figure(figsize=(14, 6))

    plt.subplot(1, 2, 1)
    plt.semilogy(df_ser['SNR_dB'], df_ser['SER_Perfect'], 'k-o', label='Perfect CSI')
    plt.semilogy(df_ser['SNR_dB'], df_ser['SER_Ideal_AI'], 'b--s', label='Ideal AI')
    plt.semilogy(df_ser['SNR_dB'], df_ser['SER_RRAM_AI'], 'r-^', label='RRAM AI')
    plt.title(f'SER Performance')
    plt.xlabel('SNR (dB)'); plt.ylabel('SER')
    plt.grid(True, which='both', linestyle='--', alpha=0.5)
    plt.legend()

    if saved_constellation_data is not None:
        plt.subplot(1, 2, 2)

        rx_data = saved_constellation_data['Rx_RRAM'].flatten()
        plt.scatter(np.real(rx_data), np.imag(rx_data),
                    c='r', s=1, alpha=0.1, label=f'RRAM Rx ({TOTAL_TEST_SYMBOLS} pts)')

        tx_data = saved_constellation_data['Tx'].flatten()
        limit = min(1000, len(tx_data))
        plt.scatter(np.real(tx_data[:limit]), np.imag(tx_data[:limit]),
                    c='k', marker='x', s=20, label='Tx (Ref)')

        plt.title(f'16-QAM Constellation @ SNR={VIZ_SNR_TARGET}dB\n(RRAM Matrix Processed)')
        plt.xlabel('I'); plt.ylabel('Q')
        plt.axis('equal'); plt.grid(True, alpha=0.3)
        plt.legend(loc='upper right')

    plt.tight_layout()
    plt.show()

if __name__ == '__main__':
    main()